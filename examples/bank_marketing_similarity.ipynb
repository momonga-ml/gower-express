{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gower Distance for Agricultural Data: Bank Marketing Classification Example\n",
    "\n",
    "This notebook demonstrates the power of **Gower distance** for analyzing mixed-type datasets. Gower distance is perfect for data where we have both numerical measurements and categorical classifications.\n",
    "\n",
    "## What is Gower Distance?\n",
    "\n",
    "Gower distance is a distance metric that can handle:\n",
    "- **Numerical features** (e.g., area, perimeter, length)\n",
    "- **Categorical features** (e.g., variety, grade, quality)\n",
    "- **Missing values** (common in real-world data)\n",
    "\n",
    "Perfect for agricultural quality control, food classification, and similarity analysis!\n",
    "\n",
    "## Dataset: Bank Marketing\n",
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "#!uv pip install gower ucimlrepo pandas numpy matplotlib seaborn plotly scikit-learn umap-learn\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from umap import UMAP\n",
    "\n",
    "import gower_exp\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Bank dataset from UCI repository\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "bank = fetch_ucirepo(id=222)\n",
    "\n",
    "X = bank.data.features\n",
    "y = bank.data.targets\n",
    "\n",
    "num_rows_to_sample = 5000\n",
    "random_row_indices = np.random.choice(\n",
    "    y.shape[0], size=num_rows_to_sample, replace=False\n",
    ")\n",
    "\n",
    "# Combine features and targets into a single DataFrame for easier analysis\n",
    "# Sampling for my Mac, you can set gpu=True and try running with the full dataset on NVIDIA\n",
    "df = pd.concat([X.iloc[random_row_indices], y.iloc[random_row_indices]], axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Features: {len(X.columns)}\")\n",
    "print(f\"Classes: {df['y'].nunique()} ({df['y'].value_counts().to_dict()})\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nüìà BASIC STATISTICS:\")\n",
    "print(\"=\" * 50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Gower Distance Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "categorical_encoding = [1 if col in categorical_columns else 0 for col in X.columns]\n",
    "print(\"Categorical features:\", list(categorical_columns))\n",
    "print(\"Categorical encoding:\", categorical_encoding)\n",
    "\n",
    "# Compute the full Gower distance matrix\n",
    "print(\"‚ö° Computing Gower Distance Matrix...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use only features (X) for distance calculation\n",
    "gower_distances = gower_exp.gower_matrix(df)\n",
    "\n",
    "computation_time = time.time() - start_time\n",
    "print(\n",
    "    f\"‚úÖ Computed {gower_distances.shape[0]:,} x {gower_distances.shape[0]:,} distance matrix in {computation_time:.2f} seconds\"\n",
    ")\n",
    "print(f\"üìè Distance range: [{gower_distances.min():.4f}, {gower_distances.max():.4f}]\")\n",
    "print(f\"üìä Mean distance: {gower_distances.mean():.4f} ¬± {gower_distances.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distance matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Full distance matrix heatmap (sample for performance)\n",
    "sample_size = min(100, len(df))\n",
    "sample_indices = np.random.choice(len(df), sample_size, replace=False)\n",
    "sample_distances = gower_distances[sample_indices][:, sample_indices]\n",
    "sample_labels = df.iloc[sample_indices][\"y\"].values\n",
    "\n",
    "im1 = axes[0].imshow(sample_distances, cmap=\"viridis\", aspect=\"auto\")\n",
    "axes[0].set_title(\n",
    "    f\"Gower Distance Matrix\\n(Random sample of {sample_size} bank clients)\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Client Index\")\n",
    "axes[0].set_ylabel(\"Client Index\")\n",
    "plt.colorbar(im1, ax=axes[0], label=\"Gower Distance\")\n",
    "\n",
    "# Distance distribution by class pairs\n",
    "class_names = df[\"y\"].unique()\n",
    "within_class_distances = []\n",
    "between_class_distances = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(i + 1, len(df)):\n",
    "        if df.iloc[i][\"y\"] == df.iloc[j][\"y\"]:\n",
    "            within_class_distances.append(gower_distances[i, j])\n",
    "        else:\n",
    "            between_class_distances.append(gower_distances[i, j])\n",
    "\n",
    "axes[1].hist(\n",
    "    within_class_distances[:5000],\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    label=\"Within-class\",\n",
    "    density=True,\n",
    ")\n",
    "axes[1].hist(\n",
    "    between_class_distances[:5000],\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    label=\"Between-class\",\n",
    "    density=True,\n",
    ")\n",
    "axes[1].set_title(\"Distance Distribution by Class Relationship\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"Gower Distance\")\n",
    "axes[1].set_ylabel(\"Density\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéØ Class Separation Analysis:\")\n",
    "print(\n",
    "    f\"‚Ä¢ Within-class distances: Œº={np.mean(within_class_distances):.3f}, œÉ={np.std(within_class_distances):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"‚Ä¢ Between-class distances: Œº={np.mean(between_class_distances):.3f}, œÉ={np.std(between_class_distances):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"‚Ä¢ Separation ratio: {np.mean(between_class_distances) / np.mean(within_class_distances):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding Similar Bank Clients - K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive example: Find similar bank clients\n",
    "def analyze_client_similarity(client_idx, n_similar=5):\n",
    "    \"\"\"\n",
    "    Find and analyze the most similar bank clients to a given client\n",
    "    \"\"\"\n",
    "    target_client = df.iloc[[client_idx]]\n",
    "    target_features = X.iloc[[client_idx]]\n",
    "\n",
    "    # Use gower_topn to find most similar clients\n",
    "    result = gower_exp.gower_topn(target_features, target_features, n=n_similar)\n",
    "    similar_indices = result[\"index\"][1:]  # Skip the first match (self)\n",
    "    distances = result[\"values\"][1:]\n",
    "\n",
    "    print(f\"üéØ TARGET CLIENT #{client_idx}\")\n",
    "    print(f\"Subscription: {target_client['y'].iloc[0]}\")\n",
    "    print(\"\\nüìä Features:\")\n",
    "    for feature in X.columns:\n",
    "        print(f\"  {feature:17}: {target_features[feature].iloc[0]}\")\n",
    "\n",
    "    print(f\"\\nüîç TOP {n_similar} MOST SIMILAR CLIENTS:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\n",
    "        f\"{'Rank':<4} {'Index':<6} {'Subscription':<12} {'Distance':<10} {'Match':<8}\"\n",
    "    )\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    class_matches = 0\n",
    "    for rank, (idx, dist) in enumerate(zip(similar_indices, distances), 1):\n",
    "        similar_class = df.iloc[idx][\"y\"]\n",
    "        is_match = similar_class == target_client[\"y\"].iloc[0]\n",
    "        if is_match:\n",
    "            class_matches += 1\n",
    "        match_str = \"‚úÖ\" if is_match else \"‚ùå\"\n",
    "        print(f\"{rank:<4} {idx:<6} {similar_class:<12} {dist:<10.4f} {match_str:<8}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nüéØ Accuracy: {class_matches}/{n_similar} ({100 * class_matches / n_similar:.1f}%) correct subscription matches\"\n",
    "    )\n",
    "\n",
    "    return similar_indices, distances\n",
    "\n",
    "\n",
    "# Analyze a few example clients\n",
    "example_indices = [0, 50, 100, 200, 400]\n",
    "print(\"üè¶ BANK CLIENT SIMILARITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, idx in enumerate(example_indices[:2]):  # Show first 2 examples\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    similar_indices, distances = analyze_client_similarity(idx, n_similar=5)\n",
    "    if i < len(example_indices) - 1:\n",
    "        print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature comparison for similar clients\n",
    "def plot_similar_clients_comparison(target_idx, similar_indices, distances):\n",
    "    \"\"\"\n",
    "    Create radar chart comparing target client with its most similar clients\n",
    "    \"\"\"\n",
    "    # Select target and top 3 similar clients\n",
    "    indices_to_plot = [target_idx] + list(similar_indices[:3])\n",
    "    num_similar = min(3, len(similar_indices))\n",
    "    labels = [\"Target\"] + [\n",
    "        f\"Similar #{i + 1}\\n(d={distances[i]:.3f})\" for i in range(num_similar)\n",
    "    ]\n",
    "    colors = [\"red\"] + [\"blue\", \"green\", \"orange\"][:num_similar]\n",
    "\n",
    "    # Only use numerical features for radar chart\n",
    "    numerical_features = X.select_dtypes(include=[np.number])\n",
    "    features_normalized = (numerical_features - numerical_features.min()) / (\n",
    "        numerical_features.max() - numerical_features.min()\n",
    "    )\n",
    "\n",
    "    # Create radar chart\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for idx, label, color in zip(indices_to_plot, labels, colors):\n",
    "        values = features_normalized.iloc[idx].values.tolist()\n",
    "        values.append(values[0])  # Close the radar chart\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatterpolar(\n",
    "                r=values,\n",
    "                theta=list(numerical_features.columns)\n",
    "                + [numerical_features.columns[0]],\n",
    "                fill=\"toself\" if idx == target_idx else None,\n",
    "                name=f\"{label} ({df.iloc[idx]['y']})\",\n",
    "                line=dict(color=color, width=3 if idx == target_idx else 2),\n",
    "                fillcolor=color if idx == target_idx else None,\n",
    "                opacity=0.3 if idx == target_idx else 0.8,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n",
    "        showlegend=True,\n",
    "        title=f\"Feature Comparison: Client #{target_idx} vs Most Similar Clients\",\n",
    "        font=dict(size=12),\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Plot comparison for first example\n",
    "target_idx = 0\n",
    "similar_indices, distances = analyze_client_similarity(target_idx, n_similar=5)\n",
    "\n",
    "# Make sure we have enough similar clients for comparison\n",
    "if len(similar_indices) > 3:\n",
    "    plot_similar_clients_comparison(target_idx, similar_indices, distances)\n",
    "else:\n",
    "    print(f\"Not enough similar clients found. Only {len(similar_indices)} available.\")\n",
    "    # Modify the function call to use only available similar clients\n",
    "    n_available = len(similar_indices)\n",
    "    if n_available > 0:\n",
    "        plot_similar_clients_comparison(\n",
    "            target_idx, similar_indices, distances[:n_available]\n",
    "        )\n",
    "    else:\n",
    "        print(\"Cannot create comparison plot: no similar clients found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Anomaly Detection - Finding Unusual Bank Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection using average Gower distances\n",
    "def detect_anomalies(distance_matrix, percentile=95):\n",
    "    \"\"\"\n",
    "    Detect anomalous bank clients based on their average distance to all others\n",
    "    \"\"\"\n",
    "    # Calculate average distance for each client\n",
    "    avg_distances = np.mean(distance_matrix, axis=1)\n",
    "\n",
    "    # Identify outliers\n",
    "    threshold = np.percentile(avg_distances, percentile)\n",
    "    outlier_indices = np.where(avg_distances > threshold)[0]\n",
    "\n",
    "    return outlier_indices, avg_distances, threshold\n",
    "\n",
    "\n",
    "# Detect outliers\n",
    "outlier_indices, avg_distances, threshold = detect_anomalies(\n",
    "    gower_distances, percentile=95\n",
    ")\n",
    "\n",
    "print(\"üö® ANOMALY DETECTION RESULTS\")\n",
    "print(f\"Threshold (95th percentile): {threshold:.4f}\")\n",
    "print(\n",
    "    f\"Number of outliers found: {len(outlier_indices)} ({100 * len(outlier_indices) / len(df):.1f}% of dataset)\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìã OUTLIER CLIENTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Index':<6} {'Subscription':<12} {'Avg Distance':<12} {'Percentile':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx in outlier_indices[:10]:  # Show top 10 outliers\n",
    "    percentile = (avg_distances < avg_distances[idx]).sum() / len(avg_distances) * 100\n",
    "    print(\n",
    "        f\"{idx:<6} {df.iloc[idx]['y']:<12} {avg_distances[idx]:<12.4f} {percentile:<10.1f}%\"\n",
    "    )\n",
    "\n",
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Distribution of average distances\n",
    "axes[0].hist(avg_distances, bins=50, alpha=0.7, color=\"skyblue\", edgecolor=\"black\")\n",
    "axes[0].axvline(\n",
    "    threshold,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"Threshold ({threshold:.4f})\",\n",
    ")\n",
    "axes[0].set_title(\"Distribution of Average Gower Distances\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Average Gower Distance\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Outliers by class\n",
    "# Outliers by class\n",
    "outlier_classes = df.iloc[outlier_indices][\"y\"].value_counts()\n",
    "normal_classes = df.iloc[~np.isin(df.index, outlier_indices)][\"y\"].value_counts()\n",
    "\n",
    "x = np.arange(len(outlier_classes.index))\n",
    "width = 0.35\n",
    "\n",
    "axes[1].bar(\n",
    "    x - width / 2,\n",
    "    outlier_classes.values,\n",
    "    width,\n",
    "    label=\"Outliers\",\n",
    "    alpha=0.8,\n",
    "    color=\"red\",\n",
    ")\n",
    "axes[1].bar(\n",
    "    x + width / 2, normal_classes.values, width, label=\"Normal\", alpha=0.8, color=\"blue\"\n",
    ")\n",
    "axes[1].set_title(\"Outlier Distribution by Subscription\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"Subscription Status\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(outlier_classes.index)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Insights:\")\n",
    "print(\"‚Ä¢ Outliers are distributed across both subscription outcomes\")\n",
    "print(\n",
    "    \"‚Ä¢ These clients have unusual combinations of demographic and behavioral features\"\n",
    ")\n",
    "print(\"‚Ä¢ Could represent unique customer segments or edge cases for targeting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Customer Profiling - Golden Standard Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate customer profiling using \"golden standard\" clients\n",
    "def customer_profiling_simulation(golden_standards, test_samples, max_distance=0.2):\n",
    "    \"\"\"\n",
    "    Simulate customer profiling by comparing test clients to golden standards\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_idx in test_samples:\n",
    "        test_client = X.iloc[[test_idx]]\n",
    "        test_class = df.iloc[test_idx][\"y\"]\n",
    "\n",
    "        # Find closest golden standard\n",
    "        min_distance = float(\"inf\")\n",
    "        closest_standard = None\n",
    "\n",
    "        for std_idx in golden_standards:\n",
    "            std_client = X.iloc[[std_idx]]\n",
    "            distance = gower_exp.gower_matrix(\n",
    "                test_client, std_client, cat_features=categorical_encoding\n",
    "            )[0, 0]\n",
    "\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_standard = std_idx\n",
    "\n",
    "        # Profile decision\n",
    "        similar = min_distance <= max_distance\n",
    "        standard_class = df.iloc[closest_standard][\"y\"]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"test_idx\": test_idx,\n",
    "                \"test_class\": test_class,\n",
    "                \"closest_standard\": closest_standard,\n",
    "                \"standard_class\": standard_class,\n",
    "                \"distance\": min_distance,\n",
    "                \"similar\": similar,\n",
    "                \"class_match\": test_class == standard_class,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Select golden standards (best representatives of each class)\n",
    "golden_standards = []\n",
    "for class_name in df[\"y\"].unique():\n",
    "    class_samples = df[df[\"y\"] == class_name].index\n",
    "\n",
    "    # Find the most \"central\" sample in each class\n",
    "    class_distances = gower_distances[class_samples][:, class_samples]\n",
    "    avg_class_distances = np.mean(class_distances, axis=1)\n",
    "    central_idx = class_samples[np.argmin(avg_class_distances)]\n",
    "    golden_standards.append(central_idx)\n",
    "\n",
    "print(\"üèÜ GOLDEN STANDARDS SELECTED:\")\n",
    "for i, std_idx in enumerate(golden_standards):\n",
    "    print(f\"Standard {i + 1}: Client #{std_idx} ({df.iloc[std_idx]['y']})\")\n",
    "\n",
    "# Test on random samples\n",
    "test_samples = np.random.choice(df.index, 50, replace=False)\n",
    "profiling_results = customer_profiling_simulation(\n",
    "    golden_standards, test_samples, max_distance=0.3\n",
    ")\n",
    "\n",
    "print(\"\\nüîç CUSTOMER PROFILING RESULTS:\")\n",
    "print(f\"Total tested: {len(profiling_results)}\")\n",
    "print(\n",
    "    f\"Similar to standards: {profiling_results['similar'].sum()} ({100 * profiling_results['similar'].mean():.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Different from standards: {(~profiling_results['similar']).sum()} ({100 * (~profiling_results['similar']).mean():.1f}%)\"\n",
    ")\n",
    "print(f\"Class accuracy: {profiling_results['class_match'].mean() * 100:.1f}%\")\n",
    "\n",
    "# Visualize profiling results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Distance distribution by profiling result\n",
    "similar_distances = profiling_results[profiling_results[\"similar\"]][\"distance\"]\n",
    "different_distances = profiling_results[~profiling_results[\"similar\"]][\"distance\"]\n",
    "\n",
    "axes[0].hist(\n",
    "    similar_distances, bins=20, alpha=0.7, label=\"Similar to standards\", color=\"green\"\n",
    ")\n",
    "axes[0].hist(\n",
    "    different_distances,\n",
    "    bins=20,\n",
    "    alpha=0.7,\n",
    "    label=\"Different from standards\",\n",
    "    color=\"red\",\n",
    ")\n",
    "axes[0].axvline(0.3, color=\"black\", linestyle=\"--\", label=\"Similarity Threshold\")\n",
    "axes[0].set_title(\"Distance to Golden Standards\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Gower Distance\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Similarity rate by class\n",
    "profiling_by_class = (\n",
    "    profiling_results.groupby([\"test_class\", \"similar\"]).size().unstack(fill_value=0)\n",
    ")\n",
    "profiling_by_class_pct = (\n",
    "    profiling_by_class.div(profiling_by_class.sum(axis=1), axis=0) * 100\n",
    ")\n",
    "\n",
    "profiling_by_class_pct.plot(kind=\"bar\", ax=axes[1], color=[\"red\", \"green\"], alpha=0.8)\n",
    "axes[1].set_title(\"Similarity Rate by Subscription Status\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"Subscription Status\")\n",
    "axes[1].set_ylabel(\"Percentage\")\n",
    "axes[1].legend([\"Different\", \"Similar\"])\n",
    "axes[1].set_xticklabels(profiling_by_class_pct.index, rotation=0)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüíº Customer Profiling Applications:\")\n",
    "print(\"‚Ä¢ Identify clients similar to high-value customer archetypes\")\n",
    "print(\"‚Ä¢ Segment customers based on similarity to representative profiles\")\n",
    "print(\"‚Ä¢ Personalize marketing strategies based on customer similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clustering Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gower distances for clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "print(\"üîó CLUSTERING WITH GOWER DISTANCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert Gower distances to distance matrix for clustering\n",
    "distance_matrix = gower_distances\n",
    "\n",
    "# Try different clustering algorithms that can work with precomputed distances\n",
    "clustering_results = {}\n",
    "\n",
    "# Hierarchical clustering\n",
    "hierarchical = AgglomerativeClustering(\n",
    "    n_clusters=2, metric=\"precomputed\", linkage=\"average\"\n",
    ")\n",
    "hierarchical_labels = hierarchical.fit_predict(distance_matrix)\n",
    "\n",
    "# DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.4, min_samples=5, metric=\"precomputed\")\n",
    "dbscan_labels = dbscan.fit_predict(distance_matrix)\n",
    "\n",
    "# Evaluate clustering performance\n",
    "true_labels = pd.Categorical(df[\"y\"]).codes\n",
    "\n",
    "hierarchical_ari = adjusted_rand_score(true_labels, hierarchical_labels)\n",
    "dbscan_ari = adjusted_rand_score(true_labels, dbscan_labels)\n",
    "\n",
    "print(\"Hierarchical Clustering:\")\n",
    "print(f\"  Adjusted Rand Index: {hierarchical_ari:.4f}\")\n",
    "print(f\"  Clusters found: {len(np.unique(hierarchical_labels))}\")\n",
    "\n",
    "print(\"\\nDBSCAN Clustering:\")\n",
    "print(f\"  Adjusted Rand Index: {dbscan_ari:.4f}\")\n",
    "print(f\"  Clusters found: {len(np.unique(dbscan_labels[dbscan_labels >= 0]))}\")\n",
    "print(f\"  Noise points: {sum(dbscan_labels == -1)}\")\n",
    "\n",
    "# Create visualization using dimensionality reduction\n",
    "# Use UMAP for visualization (works well with distance matrices)\n",
    "reducer = UMAP(n_components=2, metric=\"precomputed\", random_state=42)\n",
    "embedding = reducer.fit_transform(distance_matrix)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Original classes in UMAP space\n",
    "scatter1 = axes[0, 0].scatter(\n",
    "    embedding[:, 0], embedding[:, 1], c=true_labels, cmap=\"Set1\", alpha=0.7, s=50\n",
    ")\n",
    "axes[0, 0].set_title(\n",
    "    \"Original Subscription Status (UMAP projection)\", fontweight=\"bold\"\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"UMAP 1\")\n",
    "axes[0, 0].set_ylabel(\"UMAP 2\")\n",
    "plt.colorbar(scatter1, ax=axes[0, 0])\n",
    "\n",
    "# Hierarchical clustering results\n",
    "scatter2 = axes[0, 1].scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=hierarchical_labels,\n",
    "    cmap=\"Set2\",\n",
    "    alpha=0.7,\n",
    "    s=50,\n",
    ")\n",
    "axes[0, 1].set_title(\n",
    "    f\"Hierarchical Clustering\\n(ARI: {hierarchical_ari:.3f})\", fontweight=\"bold\"\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"UMAP 1\")\n",
    "axes[0, 1].set_ylabel(\"UMAP 2\")\n",
    "plt.colorbar(scatter2, ax=axes[0, 1])\n",
    "\n",
    "# DBSCAN clustering results\n",
    "scatter3 = axes[1, 0].scatter(\n",
    "    embedding[:, 0], embedding[:, 1], c=dbscan_labels, cmap=\"Set3\", alpha=0.7, s=50\n",
    ")\n",
    "axes[1, 0].set_title(f\"DBSCAN Clustering\\n(ARI: {dbscan_ari:.3f})\", fontweight=\"bold\")\n",
    "axes[1, 0].set_xlabel(\"UMAP 1\")\n",
    "axes[1, 0].set_ylabel(\"UMAP 2\")\n",
    "plt.colorbar(scatter3, ax=axes[1, 0])\n",
    "\n",
    "# Confusion matrix for best clustering\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "best_labels = hierarchical_labels if hierarchical_ari > dbscan_ari else dbscan_labels\n",
    "best_method = \"Hierarchical\" if hierarchical_ari > dbscan_ari else \"DBSCAN\"\n",
    "\n",
    "cm = confusion_matrix(true_labels, best_labels)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1, 1])\n",
    "axes[1, 1].set_title(f\"Confusion Matrix - {best_method}\", fontweight=\"bold\")\n",
    "axes[1, 1].set_xlabel(\"Predicted Cluster\")\n",
    "axes[1, 1].set_ylabel(\"True Subscription Status\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Clustering Insights:\")\n",
    "print(\"‚Ä¢ Gower distance successfully captures subscription structure in the data\")\n",
    "print(\n",
    "    f\"‚Ä¢ {best_method} clustering performs better with ARI = {max(hierarchical_ari, dbscan_ari):.3f}\"\n",
    ")\n",
    "print(\"‚Ä¢ UMAP visualization reveals patterns in customer similarity\")\n",
    "print(\"‚Ä¢ Distance-based clustering works well for mixed-type banking data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
